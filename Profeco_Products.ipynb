{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quien es quien es los precios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Procesamiento de los datos\n",
    "\n",
    "* ¿Cuántos registros hay?\n",
    "\n",
    "* ¿Cuántas categorías? 40\n",
    "\n",
    "* ¿Cuantás cadenas comerciales están siendo monitoreadas?\n",
    "\n",
    "* ¿Cómo podrías determinar la calidad de los datos? ¿Detectaste algún tipo de inconsistencia o error en la fuente?\n",
    "\n",
    "* ¿Cuáles son los productos más monitoreados en cada entidad?\n",
    "\n",
    "* ¿Cuál es la cadena comercial con mayor variedad de productos monitoreados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Análisis exploratorio\n",
    "\n",
    "* Genera una canasta de productos básicos que te permite comparar los precios geográfica y temporalmente. Justifica tu elección y procedimiento.\n",
    "\n",
    "* ¿Cuál es la ciudad más cara del país? ¿Cuál es la más barata?\n",
    "\n",
    "* ¿Hay algún patrón estacinal entre años?\n",
    "\n",
    "* ¿Cuál es el estado más cara y en qué mes?\n",
    "\n",
    "* ¿Cuáles son los principales riesgos de hacer análisis de series de tiempo con estos datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualización\n",
    "\n",
    "Genera un mapa que nos perimta identificar la oferta de las categorías en la zona metropolitana de León Guanajuato y el nivel de precios en cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `SparkContext` instance or reuse an existing one, and start the `SparkSession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Spark Settings to Show DataFrames more like Pandas DataFrames, load the data and check out the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read de csv file and print the Schema of the variables\n",
    "data = spark.read.option('header',True).csv('./all_data.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The data consists on an historical daily register of more than 2,000 products, from 2015, in from Mexico stores.\n",
    "It contains 62,530,715 records and 15 columns which describe the product and the store where it belongs.\n",
    "\n",
    "#### Columns\n",
    "\n",
    "* producto\n",
    "* presentación\n",
    "* marca \n",
    "* categoría\n",
    "* precio\n",
    "* fecha de registro\n",
    "* cadena comercial\n",
    "* giro\n",
    "* nombre comercial\n",
    "* dirección\n",
    "* estado\n",
    "* municipio\n",
    "* latitud \n",
    "* longitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ride of the columns we don't need.\n",
    "\n",
    "For purpuse of this project we are going to drop the next columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['presentacion','marca','nombreComercial','direccion']\n",
    "df = data.select([col for col in data.columns if col not in drop_list])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>producto</th><th>marca</th><th>categoria</th><th>catalogo</th><th>precio</th><th>fechaRegistro</th><th>cadenaComercial</th><th>giro</th><th>estado</th><th>municipio</th><th>latitud</th><th>longitud</th></tr>\n",
       "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----+---------+--------+------+-------------+---------------+----+------+---------+-------+--------+\n",
       "|producto|marca|categoria|catalogo|precio|fechaRegistro|cadenaComercial|giro|estado|municipio|latitud|longitud|\n",
       "+--------+-----+---------+--------+------+-------------+---------------+----+------+---------+-------+--------+\n",
       "|       0|    0|        0|       0|     0|            0|              0|   0|     0|        0|      0|       0|\n",
       "+--------+-----+---------+--------+------+-------------+---------------+----+------+---------+-------+--------+"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nan values\n",
    "#df.select([f.count(f.when(f.isnan(col),col)).alias(col) for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>producto</th><th>marca</th><th>categoria</th><th>catalogo</th><th>precio</th><th>fechaRegistro</th><th>cadenaComercial</th><th>giro</th><th>estado</th><th>municipio</th><th>latitud</th><th>longitud</th></tr>\n",
       "<tr><td>0</td><td>0</td><td>887338</td><td>228</td><td>20</td><td>0</td><td>1184</td><td>287</td><td>15054</td><td>15054</td><td>36814</td><td>36814</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----+---------+--------+------+-------------+---------------+----+------+---------+-------+--------+\n",
       "|producto|marca|categoria|catalogo|precio|fechaRegistro|cadenaComercial|giro|estado|municipio|latitud|longitud|\n",
       "+--------+-----+---------+--------+------+-------------+---------------+----+------+---------+-------+--------+\n",
       "|       0|    0|   887338|     228|    20|            0|           1184| 287| 15054|    15054|  36814|   36814|\n",
       "+--------+-----+---------+--------+------+-------------+---------------+----+------+---------+-------+--------+"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values\n",
    "df.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61593556"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.na.drop()\n",
    "df_clean.count() # Less than 2% of the data (62530715-61593556 = 937159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated values.\n",
    "\n",
    "We count the distinct values on the df and got that around 5% ( 3162361 rows) are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59368354"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_cat = df.groupBy('categoria').count() # 42 \n",
    "dist_cad = df.groupBy('cadenaComercial').count()\n",
    "dist_est = df.groupBy('estado').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|              estado|   count|\n",
      "+--------------------+--------+\n",
      "|        QUINTANA ROO| 2076525|\n",
      "|          NUEVO LEÓN| 3171091|\n",
      "|             SINALOA| 1720736|\n",
      "|             TABASCO| 1842633|\n",
      "|     BAJA CALIFORNIA| 1200999|\n",
      "|            TLAXCALA| 2081024|\n",
      "|COAHUILA DE ZARAGOZA| 1498109|\n",
      "|                null|   15054|\n",
      "|       ESQ. SUR 125\"|     132|\n",
      "|             CHIAPAS|  527160|\n",
      "| COL. EDUARDO GUERRA|   14364|\n",
      "|VERACRUZ DE IGNAC...|  690420|\n",
      "|              SONORA| 1698620|\n",
      "|             YUCATÁN| 2300994|\n",
      "| MICHOACÁN DE OCAMPO| 2093037|\n",
      "|             DURANGO|  563269|\n",
      "|            GUERRERO|  485470|\n",
      "|             NAYARIT|  419547|\n",
      "|           CHIHUAHUA|  919673|\n",
      "|    DISTRITO FEDERAL|11283970|\n",
      "|              estado|      20|\n",
      "|             HIDALGO| 1017667|\n",
      "|           ZACATECAS| 1383201|\n",
      "|          GUANAJUATO| 2638456|\n",
      "|     SAN LUIS POTOSÍ|  532919|\n",
      "|          TAMAULIPAS| 1170493|\n",
      "|             MORELOS|  353225|\n",
      "|      AGUASCALIENTES|  628576|\n",
      "|              OAXACA| 1075420|\n",
      "|              PUEBLA| 2021476|\n",
      "| BAJA CALIFORNIA SUR|  977128|\n",
      "|             JALISCO| 4552128|\n",
      "|            CAMPECHE|  576079|\n",
      "|           QUERÉTARO| 1667824|\n",
      "|              COLIMA| 1159974|\n",
      "|              MÉXICO| 8173302|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = dist_est.count()\n",
    "dist_est.show(n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References.\n",
    "\n",
    "https://www.ateam-oracle.com/comparison-of-data-prep-and-cleansing-for-nlp-with-pandas-dask-and-spark\n",
    "\n",
    "https://github.com/allisonhonold/spark-data-prep-blog/blob/master/data_prep_pyspark_blog.ipynb\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/pyspark-and-sparksql-basics-6cb4bf967e53\n",
    "\n",
    "\n",
    "https://hackingandslacking.com/cleaning-pyspark-dataframes-1a3f5fdcedd1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
